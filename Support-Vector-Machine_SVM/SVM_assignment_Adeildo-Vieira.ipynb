{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02834891-50ac-4ec9-a5f2-1f6f99c94760",
   "metadata": {},
   "source": [
    "# 1. Learning Objectives\n",
    "\n",
    "The objective of this lab assignment is that you should get hands-on experience with implementing and using a support vector machine from scratch. In particular, you should be able to:\n",
    "\n",
    "* Use the mathematical formulation of the optimization task,\n",
    "* Formulate the indicator function and explain how it relates to the outcome of the classification,\n",
    "* Predict and explain the outcome of using different kernels,\n",
    "* Explain the effect of the C-value when using slack variables.\n",
    "\n",
    "In addition, you will gain some experience in using Python together with the packages numpy, scipy, and matplotlib, commonly used for scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb4913-9e09-4247-97a8-a17fdc172d9a",
   "metadata": {},
   "source": [
    "# 2. Theory\n",
    "\n",
    "The idea is to build a classifier which first makes an transformation of the input data, and then a linear separation where the decision boundary is placed to give maximal margins to the available data points. The location of the decision boundary is given by the weights ($\\vec{w}$) and the bias (b) so the problem is to find the values for ($\\vec{w}$) and b which maximize the margin, i.e. the distance to any datapoint.\n",
    "\n",
    "## 2.1. Dual Formulation\n",
    "\n",
    "Given a constrained optimization problem, known as the primal problem, it is possible to express a different but closely related problem, called its dual problem, as shown in equation 5-3 of the book.\n",
    "\n",
    "Find the values $\\alpha^{(i)}$ which minimize:\n",
    "\\begin{align}\n",
    "\\frac{1}{2} \\sum_{i=1}^m  \\sum_{j=1}^m \\alpha^{(i)}  \\alpha^{(j)} t^{(i)} t^{(j)} {x^{(i)}}^T x^{(j)} -  \\sum_{i=1}^m \\alpha^{(i)}\n",
    "\\end{align}\n",
    "\n",
    "subject to the constraints $\\alpha^{(i)} \\geqslant 0$ for $ i = 1,2,...,m$  and  $\\sum_{i}   \\alpha^{(i)} t^{(i)} = 0$\n",
    "\n",
    "where we have the following notation:\n",
    "\n",
    "* $\\vec{w}$ is the weight vector defining the separating hyperplane\n",
    "* $b$ is the offset (bias) for the hyperplane\n",
    "* ${x}_i$ is the $i^{th}$ data point\n",
    "* $t_i$ is the target class (-1 or 1) for datapoint i\n",
    "\n",
    "Once you find the vector $\\hat{\\alpha}$ that minimizes this equation (using a QP solver), you can compute $\\hat{w}$ and $\\hat{b}$ that minimize the primal problem by using the primal solution shown in equation 5-4 of the book.\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{w} = \\sum_{i=1}^m \\hat{\\alpha}^{(i)} t^{(i)} x^{(i)}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\hat{b} = \\frac{1}{n_{s}} \\sum_{i=1}^m (t^{(i)} - {\\hat{w}}^T x^{(i)})\n",
    "\\end{align}\n",
    "\n",
    "## 2.2. Adding Slack Variables\n",
    "\n",
    "Instead of requiring that every datapoint is outside the margin we will allow for mistakes, quantified by variables $ \\zeta ^{i}$ (positive values; one for each datapoint). These are called slack variables. The constraints will now be\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}_{w,b,\\zeta} \\frac{1}{2} {w}^T w + C \\sum_{i=1}^m  \\zeta ^{i}\n",
    "\\end{align}\n",
    "subject to \n",
    "\\begin{align}\n",
    "t^{(i)}(w^T x^{(i)} + b) \\geqslant 1 - \\zeta ^{i} \\\\ \\text{  and  } \\zeta ^{i} \\geqslant 0 \\text{  for i = 1,2,...,m}\n",
    "\\end{align}\n",
    "\n",
    "## 2.3. Kernel Functions\n",
    "\n",
    "In Machine Learning, a kernel is a function capable of computing the dot product based only on the original vectors a and b, without having to know about the transformation. The function $K(\\vec{x}_i , \\vec{x}_j)$ is called a kernel function and computes the scalar value corresponding to $\\phi{(x_i)}· \\phi{(x_j)}$. This is, however, normally done implicitly, i.e., without actually computing the two vectors and taking their scalar product\n",
    "\n",
    "Below are some of the most commonly used kernels.\n",
    "\n",
    "Linear: $ K(a,b) = {a}^T b$\n",
    "\n",
    "Polynomial: $ K(a,b) = {({a}^T b + r)}^d $\n",
    "\n",
    "Gaussian RBF: $ K(a,b) = exp(-\\gamma {|| a - b ||}^2) $\n",
    "\n",
    "With the addition of the kernel function, we can rewrite the dual formulation equation from section 2.1 as:\n",
    "\n",
    "Find the values $\\alpha^{(i)}$ which minimize:\n",
    "\\begin{align}\n",
    "\\frac{1}{2} \\sum_{i=1}^m  \\sum_{j=1}^m \\alpha^{(i)}  \\alpha^{(j)} t^{(i)} t^{(j)} K(\\vec{x}_i , \\vec{x}_j) -  \\sum_{i=1}^m \\alpha^{(i)}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ec56f-a091-44b8-bf8a-df7262d188f0",
   "metadata": {},
   "source": [
    "# 3. Implementation\n",
    "\n",
    "We will use the general purpose optimization function minimize available in the scipy.optimize library as our QP solver. This will work well for the small problems we are dealing with here. For more complex problems, perhaps with thousands of samples, it is better to use one of the special purpose optimizers like LIBSVM developed to be efficient specifically for SVM.\n",
    "\n",
    "Start by importing minimize from scipy.optimize, along with the other packages you will need:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2843b2f6-5ae5-45ff-af9f-ad458d34be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random, math\n",
    "from scipy.optimize import minimize ## This is your QP solver\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d06a87-f11a-4238-98f1-7fce31c44786",
   "metadata": {},
   "source": [
    "The heart of your program will be a single call to the minimize function. A call to minimize should look like this pseudocode:\n",
    "```\n",
    "min_ = minimize(objective, alpha_0, bounds = B, constraints = XC)\n",
    "alpha = min_.x\n",
    "```\n",
    "This will find the vector $\\vec{\\alpha}$ which minimizes the function objective within the bounds B and the constraints XC.\n",
    "\n",
    "```objective``` is a function you have to define, which takes a vector $\\vec{\\alpha}$ as argument and returns a scalar value, effectively implementing the expression that should be minimized, in our case the dual formulation equation shown in section 2.1.\n",
    "\n",
    "```alpha_0``` is a vector with the initial guess of the $\\vec{\\alpha}$ vector. We can, e.g., simply use a vector of zeros: numpy.zeros(N). N is here the number of training samples (note that each training sample will have a corresponding ${\\alpha}$-value).\n",
    "\n",
    "B is a list of pairs of the same length as the $\\vec{\\alpha}$ -vector, stating the lower and upper bounds for the corresponding element in $\\vec{\\alpha}$. To constrain the ${\\alpha}$ values to be in the range 0 ≤ ${\\alpha}$ ≤ C, we can set ```bounds=[(0, C) for b in range(N)]```. To only have a lower bound, set the upper bound to ```None``` like this: ```bounds=[(0, None) for b in range(N)].```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2611f-df8b-403a-a479-6695855723d7",
   "metadata": {},
   "source": [
    "## 3.1 Generate test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db16961-84fe-4c27-a81b-bbd41208cd1c",
   "metadata": {},
   "source": [
    "To test your support vector machine, you will also need code for generating test data and for visualizing the results. In the following sections you will be given code fragments that you can use directly in your program to achieve this. __You will later need to move the clusters around and change their spread by changing the values in this code sample.__\n",
    "\n",
    "Hint: If you insert a call ```“numpy.random.seed(100)”``` before the code that generates the data, you will get the same random data every time you run the program. This can help during debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4103ba-9575-4469-8105-f58c2190af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "classA = np.random.randn(100, 2) * 0.3 + [1.5,0.5]\n",
    "classB = np.random.randn(200, 2) * 0.3 + [0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4ee0e4-be18-4658-ba43-709313fbd109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGgCAYAAABi2ofUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/wUlEQVR4nO3df5AU5Z348c/MAktEWBMRWG4RSETMxcTjR3SX8le0bldMKPVynia5vc3VFmruTDSEREzuEq27HBp/Xa78FWAvV6e5CBXEMqUnUuUuJMUSxVpOcyjiN/zYUQhimV0gJSj7fP/om92Z2e6Z7p5+up+n5/2q2oKd7Zl5pqe7n08/z+d5noxSSgkAAIAlskkXAAAAIAiCFwAAYBWCFwAAYBWCFwAAYBWCFwAAYBWCFwAAYBWCFwAAYBWCFwAAYBWCFwAAYBWCFwAAYBWtwcuWLVtkyZIlMn36dMlkMvLUU0+V3b6np0cymcyon9dff11nMQEAgEXG6HzxY8eOyXnnnSd/+7d/K1/84hd9P2/Xrl0yadKk4d/POOMM388dGhqSt99+WyZOnCiZTCZQeQEAQDKUUnLkyBGZPn26ZLPl21a0Bi+LFy+WxYsXB37elClT5LTTTgv1nm+//bbMmDEj1HMBAECy+vv7pampqew2WoOXsObNmyfvv/++/Omf/qn8wz/8g3zuc5/z3Pb48eNy/Pjx4d/zi2T39/cXtd4AAABzDQ4OyowZM2TixIkVtzUqeGlsbJRVq1bJggUL5Pjx4/LYY4/J5ZdfLj09PXLxxRe7PmflypVy5513jnp80qRJBC8AAFjGT8pHRuWbKjTLZDKyYcMGufrqqwM9b8mSJZLJZOTpp592/Xtpy0s+chsYGCB4AQDAEoODg9LQ0OCr/jZ+qHRzc7Ps3r3b8+/19fXDrSy0tgAAkH7GBy99fX3S2NiYdDEAAIAhtOa8HD16VN58883h3/fs2SM7duyQj33sY3LmmWfK7bffLm+99Zb853/+p4iI/Ou//qvMmjVLPvWpT8mJEyfk8ccfl/Xr18v69et1FhMAAFhEa/Cyffv2opFCy5YtExGRjo4O+Y//+A85cOCA7N+/f/jvJ06ckOXLl8tbb70lH/nIR+RTn/qUPPPMM3LllVfqLCYAALBIbAm7cQmS8AMAAMyQqoRdAACAQgQvAADAKgQvAADAKgQvAADAKgQvAIBY5HIi3d3Ov0A1CF4AANp1dYnMnCly2WXOv11dSZcINiN4AQBolcuJ3HCDyNCQ8/vQkMiNN9ICg/AIXgAAWu3ePRK45J08KVIwAbt2dFmlC8ELAECrOXNEsiW1TV2dyFlnxfP+dFmlD8ELAECrpiaRVaucgEXE+fcnP3Ee140uq3TSurYRAAAiIp2dIm1tTlfRWWfFE7iIlO+yiqsMiB7BCwAgFk1N8QcM+S6rwgAmzi4r6EG3EQAgtZLssoI+tLwAAFItqS4r6EPwAgBIvSS6rKAP3UYAAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AAMAqBC8AACQklxPp7nb+hX8ELwAAJKCrS2TmTJHLLnP+7epKukT2IHgBACBmuZzIDTeIDA05vw8Nidx4Iy0wfhG8AAAQs927RwKXvJMnRd58M/6y2Nh1RfACAECBOCrzOXNEsiU1cF2dyFln6XtPN7Z2XRG8AADwf+KqzJuaRFatcgIWEeffn/zEeTwuNnddEbwAACDxV+adnSJ79zqtPHv3Or/HyaSuq6DGJF0AAABMUK4y19Ui0tQUb2tLoXzXVeFnTqLrKgxaXgAAEHPyUOJiQtdVWFqDly1btsiSJUtk+vTpkslk5Kmnnqr4nM2bN8uCBQtk/Pjx8vGPf1weffRRnUUEAKRI0GTbwu1trszDSrrrKiytwcuxY8fkvPPOkwcffNDX9nv27JErr7xSLrroIunr65Pvfve78o1vfEPWr1+vs5gAgBQImmzrtr2tlXk1mppELr3UriAto5RSsbxRJiMbNmyQq6++2nOb2267TZ5++ml57bXXhh+76aab5H/+53+kt7fX1/sMDg5KQ0ODDAwMyKRJk6otNgDAArmcE4CU5m/s3eteKQfdHvoFqb+Nynnp7e2V1tbWosfa2tpk+/bt8sEHH7g+5/jx4zI4OFj0AwCoLUFHztg80gaGBS8HDx6UqVOnFj02depU+fDDD+Xw4cOuz1m5cqU0NDQM/8yYMSOOogIADBI02Tbq5FwbZ6m1mVHBi4jTvVQo36tV+nje7bffLgMDA8M//f392ssIADBL0GTbKJNzbZ2l1mZGzfMybdo0OXjwYNFjhw4dkjFjxsjpp5/u+pz6+nqpr6+Po3gAAIN1doq0tTldP2edVTkQCbq9G6+J7drayJ3RyajgpaWlRX75y18WPfb888/LwoULZezYsQmVCgBgi6CTvlU7SVwSE9tBc7fR0aNHZceOHbJjxw4RcYZC79ixQ/bv3y8iTpfP3/zN3wxvf9NNN8m+fftk2bJl8tprr8m///u/S1dXlyxfvlxnMQEACKXWJrYzhdbgZfv27TJv3jyZN2+eiIgsW7ZM5s2bJ9///vdFROTAgQPDgYyIyOzZs+XZZ5+Vnp4e+bM/+zP5p3/6J/m3f/s3+eIXv6izmAAAhFKLE9uZILZ5XuLCPC8AgLjlctXlziBY/W1UzgsAADZKcoHFWmTcUGkAAIByCF4AAIBVCF4AAIBVCF4AAIBvJiyFQPACAClgQoWC9DNlKQSCFwCwnCkVCtLNaymEJAJmghcAsJhJFQrSrdxSCHEjeAEAi5lUoSDdTFoKgeAFACxmUoWCdDNpKQSCFwCwmEkVCtKvs1Nk714nOXzvXuf3JLC2EQCkAGvrwHasbQQANYa1dVBL6DYCAABWIXgBAABWIXgBAABWIXgBAABWIXgBAABWIXgBABiNRSdRiuAFAGCsMItOEuykH8ELAFimVirnMItO6lphu1b2uS0IXgDAIroqZxMFXXRS1wrbtbTPbUHwAgCW0FU5myroopM6VtiutX1uC4IXALCEjsrZZEEXndSxwnat7XNbELwAgAfT8hx0VM6mC7KKsY4Vtmtxn9uA4AUAXJiY56CjcrZBU5PIpZf6+5xBgh2/7124z7NZkZUr07/PTZdRSqmkCxGlIEtqA4CbXM4JWAq7C+rqnMrQhEorl3O6Lc46y4zy1IJ77xW57TbnmMhmnYCmXGCUyzldTnPm8B35FaT+puUFAEqYnucQpCXCBqZ1z5XK5UYCF5HKSbsmtNqZvk+rRfACACXSkudgQwVmQkVfSZBg1oTRSTbs02oRvABAiTTklthQgZlQ0fsRJJiNstUuTPBpyz6tFsELALiIOvEzTrZUYKZ3z+UFCWajarULG3zask+rRfACAB5szS2xpQKzpXsulxP5+MdFensrB7NRtNpVE3zask+rRfACACljYgXm1gViQ/dcYQtIc7PI//t/3uXLf8a2tupa7aoJPm3Yp1FgqDTMwLhCIFJdXc7d+smTIxVYUl1fXV0jLQluw4xNHfodZMh8pc+o633LvYaJ+7ScIPU3wQuSF+VZD2CYCRWY6XPmlNPd7bS4uD1+6aUjv+v4jCYFn3EJUn+PialMgDuvzt22NvOvbIDhmpqSP43KdYEkXbZK8t1vpUFJafebjs/Y2elcBnt7RZQSWbQo3OukFTkvSJYtmYUAQjEt/ybI8GO/+SO6PuPGjSLXXy9y3XXmDndPCsELkmXalQ1ImA0TywVhUgJpmOHHfobM6/iMtgx3Two5L0heLXbuAi6STv/SmTefdP6Nrtybwn0mEt1n9JtvkyasbQS72DwbGBCRpO+0dc/Im/ScOTp6qEv32caN0X1GGqXLI3iBGZK+sgEJSzL9K+nAqbAc5brMqulSizoYKLfPouj6M6m7zUQELwBggCTvtMMGTlHm51Rq+am2ZSjqYMBrn/34x9G1YNEo7Y2cFwAwRFLpX0HzQXI5p5K+7z5nGK/uSdmizFeJKvfGq0xDQ84+qbactYicFwCwUFJ32kFaJfItIPfeO1JJV9vNVKnlJ8outah6qN322Te/WRy4VFNOL2kbjRYWLS+mY9p8ADGp1Crh1tpQKOxImChbXuK+ZBbuMxG9swknPRpNN1pe0kJ3+j8AFMi3Soi43927tYDkVZOfU6nlx2/LUBKXzMKWnKB5NUFaUUxJqjYFLS+msnlBkLSiFQw1oNzdvVfLS1StAH5afrz+btIl009eTdBWlFqY94WWlzRg2nyz0AqGGlDp7t6tZWH5cpF9+6LpvqiUj1Lu7yZdMit9jjCtKMz7UozgxVQcqeagvTbdyIAc5icAKE0qvuceMxoiTb5klh5iYQIt5n0pRvBiKo5Uc5h0S4do0aJWxG8AYOKckqZeMt0OsbCBFvO+jCDnxXRJLwgCszrTER2+V1e2LzWm85IZJO0tlxPZulXkS19yP8Q2brR7P+sQpP4eE1OZEFY+hR3Jyd/SlV5p+F7sVq5FrYa/285OkbY28+6Z/AYOui6ZQRJsC7ctlT/ETN3PtqDlBfCLVrBgTB+dRcuLNZKe3yToPDPl5sLhEPPGaCNABxM7+k1lQy6JqUkSKGJCvnyQtLdKc+FwiEWD4AV6MZKj9phQ2/hFBqTxTMiXD5Jg67ZtNiuybh2HWJQIXqCPDXffiJ4JtU0QtKgZzYQh0EEa6dy2XbVK5NprOcSiRM4L9DA9n8D0fAybmf7dwzqmjIAKkvZGilxw5LwgeXHdfYfplqJFSC9ySRAxU3r3gjTS0aCnFy0v0COqu+9yLSRhhiDQKhAfbj1RY2jQrQ4tL0heFHff5VpIwiaF2paPYTNuPWNFbnyyaNCNF8EL9KmmrbdScBI2CDEh+w+IGBVnsmwaYJcWBC/QK+zdd6XgJGwQkoZ8DG6xUYCKszpRnE406MaP4AVmqhScVBOEmJL9Fwa32ChBxRk+AInqdKJBN34k7MJcfsZHmpQUqjtbj2RjuKj1wyLs0gFR7zdThnPbjIRdpIOfFhJTkkLjaBHhFhsu0tATGlY1XWZRn042N+jaiJYXoFpx3frW+i02yjKpETIu3d3O/YLb45deWv65nE7moeUFiFNcLSK23mKTYBwLUxoh41RNromtpxMcBC+ASHUVbJzZera1TZNgDI2qDUBsO50wIpbg5eGHH5bZs2fL+PHjZcGCBfKrX/3Kc9uenh7JZDKjfl5//fU4igpbVRN8VFvBxn0LZ8stNmN4EYPSAKStzf+lIJ9jn7/PoIHQHtqDl7Vr18qtt94q3/ve96Svr08uuugiWbx4sezfv7/s83bt2iUHDhwY/pkzZ47uosJW1QQfUVWw3MKNRoIxYpKP5zdu9H8pKLxsnHmm80MDoT20J+xecMEFMn/+fHnkkUeGH/vkJz8pV199taxcuXLU9j09PfK5z31O3nvvPTnttNMCvx8JuzWm2qy7ajL+UB4ZkYhRkMPNbdtCdXUivb0iR48Gn/mA9Y3CMyZh98SJE/Lyyy9La2tr0eOtra2ydevWss+dN2+eNDY2yuWXXy7d3d2e2x0/flwGBweLflBDqr27T3p2qTQns5IRiRgFuRS4bVv6vAsuCN4SQ4pXfLQGL4cPH5aTJ0/K1KlTix6fOnWqHDx40PU5jY2NsmrVKlm/fr08+eSTMnfuXLn88stly5YtrtuvXLlSGhoahn9mzJgR+eeAwaoNPpKsYGvhSkd3GiJULtYPcilw27ZUvk/Cb08yKV7xiiVhN5PJFP2ulBr1WN7cuXNl6dKlMn/+fGlpaZGHH35YPv/5z8u9997ruv3tt98uAwMDwz/9/f2Rlx8GiyL4SKKCraUrnS0JxjBapVg/yKWgdNtMZiSYcQtq/DTmbt1Kilecxuh88cmTJ0tdXd2oVpZDhw6Nao0pp7m5WR5//HHXv9XX10t9fX1V5YTlOjudIQbVzNDV1BRv5VqujZtKHijiFeu3tRWfLkEuBaXbijj/nzBBpLl5dO5Mucbcri6RpUtHP876RvpoDV7GjRsnCxYskE2bNsk111wz/PimTZvkqquu8v06fX190tjYqKOISItqg4+4s+xOPdW5xQtyhSxFZiAMkMs5rQ4iIosW6TkUg8T6QS4Fpdvm/79q1eh1irxeMx9YlQ59IcVLM6XZE088ocaOHau6urrUzp071a233qomTJig9u7dq5RSasWKFaq9vX14+wceeEBt2LBBvfHGG+q3v/2tWrFihRIRtX79el/vNzAwoEREDQwMaPk8SKE1a5TKZpUScf5dsya+98v/1NUFe1+vMvf3K/XCC86/gGZr1iiVyYwcxplMdKdP4aHc3+9+yug8zPv7lerurvweL7xQXK78z7p1+sqWVkHqb+3Bi1JKPfTQQ2rmzJlq3Lhxav78+Wrz5s3Df+vo6FCXXHLJ8O933323+sQnPqHGjx+vPvrRj6oLL7xQPfPMM77fi+AFgcR9VXR7v2xWqRdfrL7MP/pRvEEYaprbYZg/9Ko9fdxi8zVrnMM8TKyvUxKBVVoFqb9ZmBG1Le55XqJ4P6/XyGSK266ZUwUaeR2G+b+FPX3Kzdci4j+1Lc5e1a6u0d1MDKwLzph5XgDjxT3PSxTv5/Ya2ezoTncdQx3SPC8NAvEabpzNVnf6VMpv8TNwLe5ZCOIcsMgp6CB4QW1LYl2iat/P7TXuvlt/EBa0RuAqm2r5w7DwsMtknMeqOX2qje+TmoUgjhkBamFqKL/oNooaI0DslMtVN9Q6ifcrfQ2dbddBp/rv6hqpQbJZp0ajHT2VcjlnKn0RkZaWaE6fag7lJFf80Hn5r4XVNoLU3wQvUeKCnRyCRoeuICxIjVALV1lo5+dQdjvtqzn8qrmMlF7+ly0TueWW6A75WliGjZyXJNTSjKmm0d2WalP3h6626yBt+awmjQhUOpS9Tnu3XtW77nIOy3KncNSL0997r7NSdVSXo6SXYTOO1nFPCUhsqLTXYP/u7njLUWt0j1MsHbN5zz21O4+K37GqjB2FZn4Osfw8LX5mEKj2kPW6/Ou4HJk4XDwqQepvWl6iQlicDJ13+W63U9/+du1my/kdUsFq0tDMz2nf1ORcflesqNwgrmNx+jCvUwnrnI4geIkKF+zydHW96Awa3a5oebXaLei3W4qrLDTye9r7DUqiXpw+7Ov4fS/WOSV4iRYXbHc6c1J0Bo3lbqdEyOOohKssNPF72vsNSqJcnH758pH35B5WH0YbQa+4Rp7oGmVTOGazFCNogET5Oe2DDLuO6jIS98wLacFQaYIXc6RhfF/+SvTSSyK3384c4IBlCCbsQPBC8GKOtM35keRVkLlsAKQY87zAHGlLZE4qj6M0b+iee+yZewYAIkbLC+JBu623Si0qbq1XeczkDGjlNYsvjaDRo+UF5mHkiTs/I7EYsg0kwu30ZHFEM9DyUmu4ZTCH33ygci0vefffL3LttXynQETcTrv8EOi0pPCZhpYXuOOWwb841jPyO4NWPm+o3Jwzy5Yl953atPYT4JPb6Tk0xLJdpiB4qRUsHOlfXEFe2Gk9Mxnnp1QS3ykBMSzkJ952Oz2zWbNWganl+waCl1phwkq/NpxpcQZ5fkdilZZJKecK+v3vj35Nv99pFN8FATEs5Dfedjs929ud0y8vm01u8GSt3zcQvNSKpBeOTPJMC1JRxx3klVtSIl/urVvdy3TuueG+06i+i6QDYhuCYRglaLxdeHr29oo89lhx8CIi0tamtciuuG8geKkduudbKVeR+DnTdFVEQSvqJII8t5FYheW+/vrR3UR1dSItLcG/0yivekkGxLV+24lQwsTb+dPz6FH3HJgk8l2Svm8wgkqZgYEBJSJqYGAg6aKYqb9fqe5u59+orFmjVDarlIjz75o1xX9/4QXnb6U/3d3+nh9Wf//I6+Z/6uqUWru2/Odfs8bZLr99FOXp73f2g5/97lbuTMa7TEG+00rfRVA69lUlXt9rkGM6yPeB1Kjm0An7XB2HWhSnQLnXTurUCFJ/E7ygOm5nUTZbHCCUO9N0noVeFbWfIKkwIKj2bA4anHmVe9266gNPHftbR0BcTrUBmK5gGVaoJt4O+tw1a5z7jvz9R5SHmo77hqRPDYIXgpf4+A0QvM60qFsCCrlV1EEr7WrP5jDBgs6ATqlor3pJ3KYlcfuMVPGKt/0czn5j9f7+kcClsAE16haYqO4bTDg1CF4IXuITJEBwO9OiPGPcrjyFFXXQICmKsoUNznR3x0Rx1UvyNi3s/tEZLMNqUR/Oa9d6N6CayIRTI0j9TcIuqlOaCFyqMIvMLTE1qkRirwTO/HCBdevck17LJZdGkRXnldR66FD5JNlyo5CiUO1yDUkPdwi7f5IedZeASrnwDNryfzineV9Zd2rEEEzFipaXhPT3O7cU1TTnh20J8NtCEvRuPapWocL3zWZH2pJtzrcw4TYtrCSSjBNSqTUh6RyHcuLskfRzOAfZV/397i0v2azZPZRJnxp0GxG8JCeJoz9IRRo0SIrq8+SDu9JOcFvzLUzoIK9G3EnGCaj0FZn8FcYdVEW5rwrLnsmMnPK2xMlJnhpB6u8xybb7IHU6O51Zm95802lvjGPqyXx7Z+lqaW7tnU1NwcoU1edpahKZPNm57hXKd0PZtqpbvrvvxhudzxD1vEG6BT0OLFSu17OpqfLfk+LVhdPWpq9clQ5nv/vKbTLsujqRn//cmZZJ537N5Zz5LEVEFi2q7lJVaaooE9b2JXhB9OKuGHRXpFF9niBBVp4pVwo3SQSq8K3S4RbmcIxDUkFVucPZ777yKvsZZ+gte1eXyNKlI/dGmYzI6tXRp8p1dY0EZ9msc9mN+j18i6ElKFZ0G9UwG7oCOjqK2547Ory3NTkhAVao1OuZdI6DG1O7s/zsqyTK7jXgM+r8mjg+W5D6O6NUaTu23QYHB6WhoUEGBgZk0qRJSRcHaRa0VSSXc0ZCld6+7d3rvhij321RM8I0xOVy5RvHKv09CV1doxtSE7vDL+BnX8Vd9u5uZ5Cl198uvVTv+0T5HkHqb7qNED+Tu0L8CtN+GqQ93ISEhKi+pzR83wYI22RfqdfTxPQfU3skS/eV26Edd9ndurREnMcmTHCCiyhOPeO6GaNr8DED3UYJqzS+MQ1dIdUscuL3eUm3nUf1PaXh+zZA0odDULWwdJRJh3ZhWfKjnDo6oi+f7m5GhkoTvCSj0tls2xXYSzVznAQ5+/1u67emCLJdFN+Tn/Gnaa/hImLTtDomVeq6mHgpy8/GsG6dUi++qHfhRl2phQQvBC/x83M2m3wFDlKRVnvlCnL2V9rWb00RpEaJ6nsq9zq1UMNFyMTK0o0t5ayWyZcypcwvnxeWB0B4Yee/9jOVvqnzT3stLeCl2iUNgkzNX27bIHOaB5nKP6rvyet1JkxIdmkBC0W1ioZuUayoYQNTL2V5ppcvCgQvGBG0Ei/k52wx8Qocdo0e3WsPlZbRLaD0W1MErVGi+p68Xufo0dqo4SIW5yEXlo5K08T1hEy8lBUyvXyRiKElKFZ0G4UURXtvkBwNU+ZjMb19tVz3it+cEq8O8LVry38Hpd9Tua61Sn8rfZ1a6FuoUVEmdZreuxjFpUxn6pdJl1o/yHkheAkuqko86NmSdNKmroo0is/lp2xeNUXpVb+jo7rFIcvVImFqGBNnR0NkoqrU0x7jmh6cxY3gheAluCSuFEmsvrZ27egWh6gr0qg+l9+A0m/Lxosvll8c0ivgKndsVHPc2HZbGFLS8bmtTG8UrVYtBGdBEbwQvIQT591w3GfumjXFlXYmM7oLJoqKNMrPFfa1yl31vf62fLl3wBXm9dJSw1SJO+vw0l65c+qMxmgjhBNnRmCcwxLySblKjTymlPNYPgswyAigcqL8XGGz7splTbr9LZsVuf9+76Tlcq/38suj3z9twxpCCpsLDodJSac6koZrYUSQTgQvKBZVJV5JnGeuW0Ah4jwWdbAU9ecKE1CWu+q7/W3ZsvIBl9friYjcdtvo91+5MmXDGsKplWHDhaKu5E0YYVXNIMxyTArObMTCjEhOXCuYuS1yKOIEGfv2RX+1MGVVuXKryBX+TcTfIpClrxfHSm0Wq7W1NcOuvWSyOL5DExfGTEqQ+pvgBcmK68wtvLKKiGQyIqtXR3N1dVudzc/nSmLBQq/3DBNwRXFlT/mijabEsbqlNVAjPo9XoPpbc/5N7EjYhafCxT+iyvoLm5EZ5HlRDVfxs/ZU0KTlapK8aySb1aZBVWEPtbQmn6Y9adg0QepvWl6AsMLebgZ5XlRt8TpvjcO0nqX1Vt1i1Rxqaf46a6X1zARB6m8SdpEucc4lHjYj0+t5vb3Fj0U5XEVn9miYJO9azGY1WLWHWpqTT01IGsZoBC9ID13DAryEHVnk9jwRkeuuKy5zlBW8aeMyTStPjYviUEtzJR/XIEz4R/CCdEhiUo2mJpH29uLH/vqvK1/hNm4snnMmT6mRMudyIu+84yQWFwpbwZt2a2xaeWpcVLEklTziQs4L0iGJYQFhOvq9hm0XWr58ZNK4fPCiVDQd7qaNyzStPDWM3A4kLUj9PSamMgH6FLZSFMbiQW4dwwzZLZe7cu21/p9TqHS223zQ8vOfi7S0VF/B5yeqM4Vp5alhnZ0ibW3EkrXOltkL6DaC3fJ5Ltdd5/yeb6kI0g3hlivjJ/HXb+6Kn+fky+w12+0ZZ5h9JUEq0O1T2+JOG6wG3UYwW7nbAK9umyCtFG6vkck4P37GjBa2tRcq131U2j5/110iCxcGm+3WRpVu6Wy55QNSyITh7gyVRrx0DU+udBvg1W0TpJXC7TWU8p/429kp8l//NfrxckM1SodlLF8+crubZCKrzmHmlb5Lm275gBSybfYCWl5QHV0Lmvi5DYhqevpKCbQi5RN/ddyyxJ3IqnNhmkr7x4RbPqDGmXAa0vKCeOgcnuznNiBoK4Vby0Lpa2SzwYcn62gt8Zt8EEVrie5h5pW+S9tu+YAUsm32AoIXhKez0vE78YTfmbHKdUsUvsa+fc6CjUHP4CRm6AqbaFxKd/BQ6btkwjrACDZNNEi3UZrEnfCou50xqoknws7HYvKYUbfPlM2OrB8XpOsnjvbiSt8lk4wAoaQpz51uo1qURMKjjnbGwpaDqG4DwrQsmD5m1O0zDQ2NzHMTpOsnjvbiSt+lTbd8gCFqOc+dlpc0SDrTKqpWiiSTf20TRaKx22ua3NoEGCTpFo80XtZoeak1SSc8RtFKEUXSqFe+h66WhThXsC7l9pmqXQep8HtM8rPBemk/fExo8Uj6sp80gpc0SEPCY7VnYqWrSZhuiXJX4LivXm5lKf1MYRKN3ZhwZYa10n74JLEGrJs0XParolJmYGBAiYgaGBhIuijxWrNGqbo6J12zrs753Qb9/Uq98IJSL76oVDabTzcd+Rz9/f5eI+xzvaxZM/Ka2Wzx/tTxfn7LkskotXy5+3v19yu1dq1S69aFL0vcnw2pUguHzwsvFH++/E93d/xlsfWy7yVI/U3LS1rYmPBYeIvW3CzS3h6u5SDq9tNKt1ZxtteWlkUpkXvvHX1LW7jG0/XXi2zcGO79ar0tGlWphcPHpBYPGy/7USFhF8nwyjbr7RU5dixY0mjUmWvd3U5AVer++0dWi44rU86rLIXvGWV54soCTDrbEVqkMYnUDSP79SBhtxbYnhHndYt27Fjw5F8/CblB9pfXys/LljlX5o0bq08A9luecqtQ529po7zdjWPYdLVJEbYf+ykW5PCx+Wus5RYPY2jvxFJKPfTQQ2rWrFmqvr5ezZ8/X23ZsqXs9j09PWr+/Pmqvr5ezZ49Wz3yyCO+36smcl7K5WPYopocFy/9/U7Hc+lrhNlfhZ3JpT/5cnq9n5/X9lueNWucPJdK5YhrX1ar2rKadOzn87XSlNARkUqHj0lfI8wRpP7WHrw88cQTauzYsWr16tVq586d6pZbblETJkxQ+/btc93+d7/7nTrllFPULbfconbu3KlWr16txo4dq37xi1/4er/UBy9pyIgrvHIVfgYdV7Bq9ld/v1L33x9tdl6Q8rht67W/3DL3TKxcq8l2NOnYp/YNzaSvEWYxKng5//zz1U033VT02DnnnKNWrFjhuv13vvMddc455xQ9duONN6rm5mZf75f64MWkVPcw3K5c2azTEuPnuUEr42r3V9RX2iDl8dr2gQe8g5387a6plWs1+9OUY5/atyqmfI0wjzGjjU6cOCEvv/yytLa2Fj3e2toqW7dudX1Ob2/vqO3b2tpk+/bt8sEHH4za/vjx4zI4OFj0k2ompbqH4TWt/bFj5Z8XNk+i2v0VdQ5IkPJ4bfuXf+n+/vlJ5kTMmIjCTTX705RjvxaG1Ghkytfol825OWmmNXg5fPiwnDx5UqZOnVr0+NSpU+XgwYOuzzl48KDr9h9++KEcPnx41PYrV66UhoaG4Z8ZM2ZE9wFMZNu65aXCXLmqmRUqiv0VZXZe0PIsWzayv/yW3fTKNez+NOXYt632NYwpX6MfaZ9wz2o6m4DeeustJSJq69atRY//8z//s5o7d67rc+bMmaP+5V/+peixX//610pE1IEDB0Zt//7776uBgYHhn/7+/nR3G+XpSqiMQ9CZlaJoZ9a5v8J0ZwXNaPSamM7rtUuTfLNZO48VNyYc+2mbHSwBJnyN5dA7GL8g3UZjdAZGkydPlrq6ulGtLIcOHRrVupI3bdo01+3HjBkjp59++qjt6+vrpb6+PrpC26KpKdlblWrm6ejsFGlr878IYP5Ot3TyiKDr9ujYX2EXkyxXHreWpgceELnllvDlTNN0Tkkf+yLBj2GMYsLXWE65BkyTy10rtHYbjRs3ThYsWCCbNm0qenzTpk2yaNEi1+e0tLSM2v7555+XhQsXytixY7WVFQFE0ZbqdzHHfJB0993mtTPrWuQkaLdPaaf87t2jgxWlzOk2SosoFiSFsegdNJzuZqD8UOmuri61c+dOdeutt6oJEyaovXv3KqWUWrFihWpvbx/ePj9U+pvf/KbauXOn6urqYqi0SeJsSy3tOvnRj8xqZ9Y1bCLIPnYbVUR7NxCJKHoHTZyxwFRGDZVWypmkbubMmWrcuHFq/vz5avPmzcN/6+joUJdccknR9j09PWrevHlq3LhxatasWUxSZ5Ko8k8qnc02VMA6y+jnqlnu/f1edZO8snJVhwWqyc0xdcYCUxkXvMSJ4EWzOGZI7e9X6r777JgMQmfiZqWrZqVA0uRpTrmqI+VsuP8yTZD6m4UZEVzYVcn8rNpWmABbKswKb3EsAJjLJZO4Wc0qeOWeK6J3n9XK6n2oaV5rqnZ3j0zHhGIszAi9ws7TUSkRtTQBtlCYJN24JmlIKnEzzIQZ+eTerVvdv4sf/1j/PjN9HhogAiT86kXLC+JT6Y7b61blgQe8Z5UN+15p4rflp7BVK5NxHis8/fNXWt37rJa+G9S0sI3UtYqWF5ipUktB0Onwy/Fzd5+Web/9tPyUtmrlg5bC72LZsnhaRGyaYhWoQpSTc6MYLS+IX7mWgqhuVSrd3YedXM5WXq1a69aJnHHGSFt2nC0iSeUKATBSkPqb4AUj4khu9fOeUVVqXoFQlN0WXuWPez9W4vczhwkeTfy8AKxDt5EuaelmcJPECmRe7xlVAqxXm21UCaNu5Y9iP+o4zvx21QRt52blOgAJoOXFrzR3MySRQBnXe3q1jFT73l6vMTRUnAQb9HV1H2eVWrWCtKKQeAsgQrS8RE3XGjamSGLoqq73LGy1KNeyU23CqFf5S+8FvD6TW+tKHMdZuVatoK0ocR83aW75BBAIwYsfaZ+XQueEBF4Vjo73LKx8zzxTZOlS70Ag7DCA/Oc59VT38ueHIJf7TF5BQpLHWZjAKc6JLOieAlCA4MWPtM82pGvoarkKJ+r3dBsKXKkVJGhuTeHnaW4WaW8fXf7Vq8t/plxudFB1ww3O42GPsyhaJMIETnENeU57yyeA4LQtUpAQbWsb6VzDxhTVrEDm9lp+FvYI+56li/p5rfMT1cIiXp/nxRdHl7/cZ1q71r1s69Y5fw96nEW1RlA1C7FEedy40bV6NwCjBKm/xyQdPFmjs1OkrS3d81I0NUX3ucrdyRe+R5j3dEtqbWtzumy88s+rbRXw+jzHjo1eqKSa/RjkOPNqkWhrC/7++VaU0mHSfl4nyuPGTb5FqjQxOC0tnxFhxDpqCd1GQSS1ho2NdHW1eVXYIiLf+pb7cx54oPrpLb0+z6FDwbovFi0anReTyYi0tIz8XnqceXULRZ0jY+p0oMzIWxEpQag1BC/QQ1eFU67CvuWW6JYXKFX6efItAddd5yQHf/vb/oKYpiYnLyZfzmzW+d1r2PK3v+28vlutpCNANDVANzWwMgApQahFzPMCvaKeAt7PtP86V0LL5UR6e52gpfTUCTIvS6X9Utg1Vqh0HhWbVn6jX0MLr5UfurtH92gCJmN5AIKXdCutsO+6S2TBgpFKUfeaOV61hYgTwOzbV937ugVope9fWCvZsEZQmid5TBhzBSItmKQO6VbYhbBypchttxV3q+ju+nDrrskbGhL58Y+re323rrE8t24hU7t68ujX0IqUINQighfYqanJqcRXrIi/UszXFl4BzAMPVFcGr+Aom42+Vopj1tq0T/JoAFKCUGsIXmCvJCvFzk6ne+iv/mr038KWIR9IiIy+lV6+3Hm/KGuluIaopH2SR0OY3gAHRIngBf6YuK5M0pViU5PIffdFU4bSQEKk+Fb6nnuib3GJqyvHrV9j5Uon+DTpeAJgDYIXVGbqJBK6O/v9BGxRlKHc3DW6bqXjbrUq7Ne46y6nu8+04wmANRhthPJeeknkgguKhwWbNpRBx2iboKNj/JTBa6hwEmNdkxqiwtAYaMAo/HRgtBGi0dXlLEBYaYHDpEXd2R+mS6VSGcq1Xvnt/oqy6y6pISok7yJipjYMQy+CF7grrcALmZJsqSsPJ+oKtlIw1NTkrFBd6K//ujiQ0HGFTmKIStJ5SkgVRuHXLoIXuPOaa0THcN0wdN1u5XIi77wzev2hairYSsFQLify2GPFf3/88ZErsM4rdNxDVJiUBBGiIa92sao03Lmt5JvNimzbJvLZzyZXLhHvyvwznxE5ejR8x3dhnksmM7JKdbUVbKVVkSutwO13hW5b1MIK7YgFC47XLlpe4M7tDnnVqvgCl3JdQlu3ulfmF1wQviWmNCBSyrkqrltXfZdKpdaGSl0paexqYVISRICGvNpF8AJvSU3bWa5LqKtL5Etfcn9ePrE4aLdKLucEKW4BUVSd5+X2ZaUrMFdowBOzC9cmhkrDLOWG0oq4L1iY794p5WeosdfqzYXiWkiw0nBrGxZgBICQGCoNe5XL7/BKIn744XDdKuVGVBWKc82kcl0pdLUAgIgQvMA0bvkd2azIoUMip57qHqR84Qv+ulVK82i8gqG/+7vRjzGEAQCMQfACs5Tmd+S7hK67zpkwr73dPUip1PHtlkfjlQj71a+mL0EWAFKEnBeYKZcT6e0Vuf760fkvvb0ix475z/0ol0ezcaPTJXTy5Egw1NnpBDdujwMAtAhSfzPPS60wffGP0vI1NYlMnuye/3LsmL81f/Kv+c473nk0XnOOMBcJABiL4KUWBF1kMG5e5atmBqrS1ywdkVT4OvlgqZTX4wCARJHzknamL/5Rrnxh5zdxe81MZiSPhXlSAMBqtLyknelTy1cqX5juG7fXHBpyJqI74wy6gQDUJNOzB4IgeEk70xf/8FO+oN03Xq/Z0lL9GZumsx9AzTA9eyAouo3SzvSp5XWUT9dn1rWSNQBoZHr2QBgMla4Vpk8tr6N8Ub5mueHWJu5PAPg/3d3OPZfb434GbsaFodIYzfSRMzrKF+Vrmp47BAAeTM8eCINuI8APr9l4bT77AdQE07MHwiB4AfxI49kPoGZUWkHFNuS8AEGYnjsEAJYi5wXxy+VEtm51/r9oUXordtNzhwCgBhC8oHpdXSJLl45Mv5/JiKxe7d0uyVwpAIAqkPOC6uRyxYGLiPN/r0kEmCsFAFAlghdUZ/fu4sAlLz+MuFAaZ0oqJ5dzsuP8fr6g2wNAjSJ4QXXmzHG6iUq5DSMuN1dK2gRtYXLb3tRgxtRyAagZBC+oTlOTk99SGMBks+7DiGtlrpSgLUxu299wg8iZZ5rTvZYPWO69l24/AIkjeEH1OjtF9u93Vm1et05k3z73ZN1amSslaAuT1yrY+e64pLvXCluFvv3t2un2A2AsRhshGk1NItdeW3m7zk6RtjZ9c6WYMJIp6FzcbtuXSmopgtJWIVPKBaCm0fKC+DU1OauBRbkAY3e3yD33mNGlEbSFyW370jwir+BHd/6JW6uQn3IBgEbMsIvwTGjl6OrybhlIetXnoLPxFm6/caPTJXPy5EjwU9oVV/jZs1knAIp6zm+31bTzvMoFACEEqb8JXhBOHBVnJeUq1ryk13yvJsArF/y4fXZdwVpXV3EgtXKlyGc/yxIJACLF8gDQy2s0TVtbvJWZ6V0a1QZ45ZYiKJcUHPV3oDtPCQACIucFwZkyX4vb0Ou8pEcy6Z6QL+5h51HnKQFAFQheEJwp87W4Jbrec48Za77rDvBqZdi5LZi4D4gVOS8IpzQPIsnEzaCJsXGIKyfFxM9ea0zI/wJSgIRdgpd4UHGWZ1KABz3iTJwGUo6EXcSjXEIpSHStBXEmTgMYRvAC6ESAl25BZ1MGEAkSdmEnEiRhAhKngUQQvMA+hQsFxrkMAAGTP7W2nzo7nRwXE0a5ATWC4AV20T1/ipekAibb1Op+Yh4cIFYEL7BLEhPkJRUw2Yb9BCAmWoOX9957T9rb26WhoUEaGhqkvb1d/vCHP5R9zle/+lXJZDJFP83NzTqLmX5pasZPYoI8U2YUNh37CUBMtAYvX/7yl2XHjh3y3HPPyXPPPSc7duyQ9vb2is+74oor5MCBA8M/zz77rM5iplvamvGTSJA0ZUZh07GfAMRE21Dp1157TZ577jnZtm2bXHDBBSIisnr1amlpaZFdu3bJ3LlzPZ9bX18v06ZN01W02mHKAopRi3v+lHzAVDrhnM37UAf2E4CYaAteent7paGhYThwERFpbm6WhoYG2bp1a9ngpaenR6ZMmSKnnXaaXHLJJfLDH/5QpkyZoquo6ZXmCbTimj8ll3P2Y1ubM5KkMGDK/23OHPv3Z1SYmA9ADLQFLwcPHnQNOKZMmSIHDx70fN7ixYvl2muvlZkzZ8qePXvkH//xH+Wyyy6Tl19+Werr60dtf/z4cTl+/Pjw74ODg9F8gDRgAq3quK1Z09bmBCw//7nIihWsZ+OGifkAaBY45+WOO+4YlVBb+rN9+3YREclkMqOer5RyfTzvuuuuk89//vNy7rnnypIlS+S///u/5Y033pBnnnnGdfuVK1cOJwQ3NDTIjBkzgn6k9GICrfDcutyWLh3JH/rOdxhVAwAJCdzycvPNN8v1119fdptZs2bJK6+8Ir///e9H/e2dd96RqVOn+n6/xsZGmTlzpuzevdv177fffrssW7Zs+PfBwUECmEI044fj1uWmlPPjJi3dcQBggcDBy+TJk2Xy5MkVt2tpaZGBgQF58cUX5fzzzxcRkd/85jcyMDAgixYt8v1+7777rvT390tjY6Pr3+vr6127k1CAZvzg3LrcyqE7DgBio22o9Cc/+Um54oorZOnSpbJt2zbZtm2bLF26VL7whS8UJeuec845smHDBhEROXr0qCxfvlx6e3tl79690tPTI0uWLJHJkyfLNddco6uowGilXW7ZrIhXdyfdcQAQK63zvPzsZz+TT3/609La2iqtra3ymc98Rh577LGibXbt2iUDAwMiIlJXVyevvvqqXHXVVXL22WdLR0eHnH322dLb2ysTJ07UWVRgtMI1a/btE1m9ujh/6J57WM8GABKQUcqrE99Og4OD0tDQIAMDAzJp0qSki4O0yeXIHwIADYLU39qGSgOpRP4QACSOhRkBAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF4AAIBVCF6AoHI5ke5u518AQOwIXoAgurpEZs4Uuewy59+urqRLBAA1h+AFKFSuVSWXE7nhBpGhIef3oSGRG2+kBQYAYkbwAuRValXZvXskcMk7eVLkzTfjKyMAgOAFEBF/rSpz5ohkS06ZujqRs86Kr5wAAIIXQET8tao0NYmsWuUELCLOvz/5ifM4ACA2Y5IuAOBLLucEGHPm6AkW8q0qhQGMW6tKZ6dIW5sT1Jx1FoELACSAlheYL44RPkFaVZqaRC69lMAFABKSUUqppAsRpcHBQWloaJCBgQGZNGlS0sVBtXI5J2ApbRHZu1dP8JDL0aoCAAkIUn/TbQSzlctF0RFcNDURtACA4eg2gtkY4QMAKEHwArMxwgcAUIJuI5iPET4AgAIEL7ADuSgAgP9DtxEAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALAKwQsAALBK6tY2UkqJiMjg4GDCJQEAAH7l6+18PV5O6oKXI0eOiIjIjBkzEi4JAAAI6siRI9LQ0FB2m4zyE+JYZGhoSN5++22ZOHGiHDlyRGbMmCH9/f0yadKkpItmlcHBQfZdCOy38Nh34bDfwmPfhaNrvyml5MiRIzJ9+nTJZstntaSu5SWbzUpTU5OIiGQyGRERmTRpEgdmSOy7cNhv4bHvwmG/hce+C0fHfqvU4pJHwi4AALAKwQsAALBKqoOX+vp6+cEPfiD19fVJF8U67Ltw2G/hse/CYb+Fx74Lx4T9lrqEXQAAkG6pbnkBAADpQ/ACAACsQvACAACsQvACAACskrrg5Yc//KEsWrRITjnlFDnttNN8PUcpJXfccYdMnz5dPvKRj8ill14q//u//6u3oIZ57733pL29XRoaGqShoUHa29vlD3/4Q9nnfPWrX5VMJlP009zcHE+BE/Twww/L7NmzZfz48bJgwQL51a9+VXb7zZs3y4IFC2T8+PHy8Y9/XB599NGYSmqWIPutp6dn1LGVyWTk9ddfj7HEZtiyZYssWbJEpk+fLplMRp566qmKz+GYC77fOOYcK1eulM9+9rMyceJEmTJlilx99dWya9euis+L+5hLXfBy4sQJufbaa+VrX/ua7+f86Ec/kvvvv18efPBBeemll2TatGny53/+58PrJNWCL3/5y7Jjxw557rnn5LnnnpMdO3ZIe3t7xeddccUVcuDAgeGfZ599NobSJmft2rVy6623yve+9z3p6+uTiy66SBYvXiz79+933X7Pnj1y5ZVXykUXXSR9fX3y3e9+V77xjW/I+vXrYy55soLut7xdu3YVHV9z5syJqcTmOHbsmJx33nny4IMP+tqeY84RdL/l1foxt3nzZvn7v/972bZtm2zatEk+/PBDaW1tlWPHjnk+J5FjTqXUT3/6U9XQ0FBxu6GhITVt2jR11113DT/2/vvvq4aGBvXoo49qLKE5du7cqUREbdu2bfix3t5eJSLq9ddf93xeR0eHuuqqq2IooTnOP/98ddNNNxU9ds4556gVK1a4bv+d73xHnXPOOUWP3Xjjjaq5uVlbGU0UdL91d3crEVHvvfdeDKWzh4ioDRs2lN2GY240P/uNY87doUOHlIiozZs3e26TxDGXupaXoPbs2SMHDx6U1tbW4cfq6+vlkksuka1btyZYsvj09vZKQ0ODXHDBBcOPNTc3S0NDQ8V90NPTI1OmTJGzzz5bli5dKocOHdJd3MScOHFCXn755aJjRUSktbXVcz/19vaO2r6trU22b98uH3zwgbaymiTMfsubN2+eNDY2yuWXXy7d3d06i5kaHHPV4ZgrNjAwICIiH/vYxzy3SeKYq/ng5eDBgyIiMnXq1KLHp06dOvy3tDt48KBMmTJl1ONTpkwpuw8WL14sP/vZz+SFF16Q++67T1566SW57LLL5Pjx4zqLm5jDhw/LyZMnAx0rBw8edN3+ww8/lMOHD2srq0nC7LfGxkZZtWqVrF+/Xp588kmZO3euXH755bJly5Y4imw1jrlwOOZGU0rJsmXL5MILL5Rzzz3Xc7skjjkrVpW+44475M477yy7zUsvvSQLFy4M/R75FajzlFKjHrON3/0mMvrzi1TeB9ddd93w/88991xZuHChzJw5U5555hn5i7/4i5ClNl/QY8Vte7fH0y7Ifps7d67MnTt3+PeWlhbp7++Xe++9Vy6++GKt5UwDjrngOOZGu/nmm+WVV16RX//61xW3jfuYsyJ4ufnmm+X6668vu82sWbNCvfa0adNExIkcGxsbhx8/dOjQqEjSNn732yuvvCK///3vR/3tnXfeCbQPGhsbZebMmbJ79+7AZbXB5MmTpa6ublRrQbljZdq0aa7bjxkzRk4//XRtZTVJmP3mprm5WR5//PGoi5c6HHPRqeVj7utf/7o8/fTTsmXLFmlqaiq7bRLHnBXBy+TJk2Xy5MlaXnv27Nkybdo02bRpk8ybN09EnD76zZs3y913363lPePid7+1tLTIwMCAvPjii3L++eeLiMhvfvMbGRgYkEWLFvl+v3fffVf6+/uLgsA0GTdunCxYsEA2bdok11xzzfDjmzZtkquuusr1OS0tLfLLX/6y6LHnn39eFi5cKGPHjtVaXlOE2W9u+vr6UntsRYljLjq1eMwppeTrX/+6bNiwQXp6emT27NkVn5PIMactFTgh+/btU319ferOO+9Up556qurr61N9fX3qyJEjw9vMnTtXPfnkk8O/33XXXaqhoUE9+eST6tVXX1Vf+tKXVGNjoxocHEziIyTiiiuuUJ/5zGdUb2+v6u3tVZ/+9KfVF77whaJtCvfbkSNH1Le+9S21detWtWfPHtXd3a1aWlrUn/zJn6R6vz3xxBNq7NixqqurS+3cuVPdeuutasKECWrv3r1KKaVWrFih2tvbh7f/3e9+p0455RT1zW9+U+3cuVN1dXWpsWPHql/84hdJfYREBN1vDzzwgNqwYYN644031G9/+1u1YsUKJSJq/fr1SX2ExBw5cmT4OiYi6v7771d9fX1q3759SimOOS9B9xvHnONrX/uaamhoUD09PerAgQPDP3/84x+HtzHhmEtd8NLR0aFEZNRPd3f38DYion76058O/z40NKR+8IMfqGnTpqn6+np18cUXq1dffTX+wifo3XffVV/5ylfUxIkT1cSJE9VXvvKVUUMGC/fbH//4R9Xa2qrOOOMMNXbsWHXmmWeqjo4OtX///vgLH7OHHnpIzZw5U40bN07Nnz+/aAhhR0eHuuSSS4q27+npUfPmzVPjxo1Ts2bNUo888kjMJTZDkP129913q0984hNq/Pjx6qMf/ai68MIL1TPPPJNAqZOXH8Jb+tPR0aGU4pjzEnS/ccw53PZZaZ1pwjGX+b/CAgAAWKHmh0oDAAC7ELwAAACrELwAAACrELwAAACrELwAAACrELwAAACrELwAAACrELwAAACrELwAAACrELwAAACrELwAAACrELwAAACr/H8NAE2foyMZrAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us see how our dataset looks\n",
    "plt.plot( [ p[0] for p in classA], [ p[1] for p in classA], 'b. ' )\n",
    "plt.plot( [ p[0] for p in classB], [ p[1] for p in classB], 'r. ' )\n",
    "\n",
    "xgrid = np.linspace(-5, 5)\n",
    "ygrid = np.linspace(-3, 3)\n",
    "\n",
    "plt.axis('equal')           # Force same scale on both axes\n",
    "plt .show()                 # Show the plot on the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39cc9bc-77da-4195-90c3-6336aebfb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors with inputs and targets\n",
    "inputs = np.concatenate((classA , classB))  # x and y coordinates for the data\n",
    "targets = np.concatenate((np.ones(classA.shape[0]), -np.ones(classB.shape[0])))  # holds the +1 or -1 values for the inputs, their indices in the list coincide respectively\n",
    "\n",
    "n_train = inputs.shape[0]  # Number of samples\n",
    "\n",
    "#The last four lines randomly reorder the samples. \n",
    "permute = list(range(n_train))\n",
    "random.shuffle(permute)\n",
    "inputs = inputs[permute, : ]  # Training values\n",
    "targets = targets[permute]    # Training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bef11-831f-434d-aef2-f35685b827b2",
   "metadata": {},
   "source": [
    "## 3.2. For you to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7095e-09ae-4d38-9de3-76169592d5df",
   "metadata": {},
   "source": [
    "You will have to write code for:\n",
    "\n",
    "### 3.2.1 A suitable kernel function:\n",
    "  \n",
    "The kernel function takes two data points as arguments and returns a “scalar product-like” similarity measure; a scalar value. Start with the linear kernel which is the same as an ordinary scalar product, but also explore the other kernels in section 2.3. Create a function for each kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdb1808-1e12-45e3-8320-00cc7ae3dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Let gamma and r in the polynomial be 1\n",
    "\n",
    "degree = 2 #hyperparameter for polynomial kernel\n",
    "gamma = 1 #hyperparameter for rbf kernel\n",
    "\n",
    "def linearKernel(x, y):\n",
    "    # return ## TO DO ##\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def polyKernel(x, y, degree, r=1):\n",
    "    # return ## TO DO ##\n",
    "    return (np.dot(x, y) + r) ** degree\n",
    "\n",
    "def rbfKernel(x, y, gamma):\n",
    "    # return ## TO DO ##\n",
    "    return np.exp(-gamma * np.linalg.norm(x - y)**2)\n",
    "\n",
    "# Set which kernel you want to use\n",
    "kernel = linearKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc83c9c-2cd8-46cb-9598-0bd81339a994",
   "metadata": {},
   "source": [
    "### 3.2.2 Implement the function objective\n",
    "\n",
    "Define a function which implements the dual formulation equation shown in section 2.1. This function will only receive the vector $\\vec{\\alpha}$ as a parameter. You can use global variables for other things that the function needs (t and K values).\n",
    "\n",
    "Python hint: This function will be called hundreds of times, so it makes sense to care about efficiency.\n",
    "\n",
    "You can pre-compute a matrix with these values:\n",
    "\\begin{align}\n",
    "P_{i,j} = t_{i}t_{j}K(x_i,x_j)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c7be44-e4b1-4ce6-ba6d-73476c7e2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate P matrix\n",
    "\n",
    "def __compute_P_mat(t, x, kernel):\n",
    "        P = np.zeros((len(x), len(x)))\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                # P[i][j] = ## TO DO ##\n",
    "                P[i][j] = t[i] * t[j] * kernel(x[i], x[j])\n",
    "        return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8d20b-334c-4d2a-bd1b-9806c0885818",
   "metadata": {},
   "source": [
    "Indices i and j run over all the data points. Thus, if you have N data points, P should be an N × N matrix. This matrix should be computed only once, outside of the function objective. Therefore, store it as a numpy array in a global variable.\n",
    "Inside the ```objective``` function, you can now make use of the functions ```numpy.dot``` (for vector-vector, vector-matrix, and matrix-vector multiplications), and numpy.sum (for summing the elements of a vector). This is much faster than explicit for-loops in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24c156a-3967-4df3-bdaa-75cf42a6057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function which we want to minimize\n",
    "\n",
    "def __objective(alpha):\n",
    "        # return ## TO DO ##\n",
    "        return 0.5 * np.dot(alpha, np.dot(P, alpha)) - np.sum(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48364467-02c4-4cde-87c5-20159942af14",
   "metadata": {},
   "source": [
    "### 3.2.3 Implement the function zerofun\n",
    "This function should implement the equality constraint in section 2.1. Also here, you can make use of numpy.dot to be efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee39a379-3fda-43cd-93a0-c00d98c70d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __zerofun(alpha):\n",
    "#         return np.dot(np.transpose(alpha), targets)\n",
    "\n",
    "def __zerofun(alpha, targets):\n",
    "    return np.dot(alpha, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b91c5-a621-4e58-b10f-4a54e04e97fc",
   "metadata": {},
   "source": [
    "### 3.2.4 Call minimize\n",
    "Make the call to minimize as indicated in the code sample given in the introduction of section 3. Note that minimize returns a dictionary data structure; this is why we must must use the string 'x' as an index to pick out the actual ${\\alpha}$ values. There are other useful indices that you can use; in particular, the index 'success' holds a boolean value which is True if the optimizer actually found a solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68702c4-8e55-47b8-94ef-4cd35235cfad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__zerofun() missing 1 required positional argument: 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m bounds \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, C) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_train)]\n\u001b[1;32m      8\u001b[0m constraint \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m:__zerofun}\n\u001b[0;32m---> 10\u001b[0m __min \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# use the string 'x' as an index to pick out the actual alpha values\u001b[39;00m\n\u001b[1;32m     13\u001b[0m alpha \u001b[38;5;241m=\u001b[39m __min\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m/opt/conda/envs/homl3/lib/python3.10/site-packages/scipy/optimize/_minimize.py:719\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    717\u001b[0m                            bounds\u001b[38;5;241m=\u001b[39mbounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslsqp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 719\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_slsqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    722\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    723\u001b[0m                                        bounds, constraints,\n\u001b[1;32m    724\u001b[0m                                        callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/conda/envs/homl3/lib/python3.10/site-packages/scipy/optimize/_slsqp_py.py:327\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    313\u001b[0m exit_modes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient evaluation required (g & a)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m                \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization terminated successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    315\u001b[0m                \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction evaluation required (f & c)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m                \u001b[38;5;241m8\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive directional derivative for linesearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m                \u001b[38;5;241m9\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration limit reached\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Set the parameters that SLSQP will need\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# meq, mieq: number of equality and inequality constraints\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m meq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, [atleast_1d(c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m](x, \u001b[38;5;241m*\u001b[39mc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    328\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cons[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m    329\u001b[0m mieq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, [atleast_1d(c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m](x, \u001b[38;5;241m*\u001b[39mc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    330\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cons[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mineq\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# m = The total number of constraints\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/homl3/lib/python3.10/site-packages/scipy/optimize/_slsqp_py.py:327\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    313\u001b[0m exit_modes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient evaluation required (g & a)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m                \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization terminated successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    315\u001b[0m                \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction evaluation required (f & c)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m                \u001b[38;5;241m8\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive directional derivative for linesearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m                \u001b[38;5;241m9\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration limit reached\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Set the parameters that SLSQP will need\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# meq, mieq: number of equality and inequality constraints\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m meq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, [atleast_1d(\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    328\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cons[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m    329\u001b[0m mieq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, [atleast_1d(c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m](x, \u001b[38;5;241m*\u001b[39mc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    330\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cons[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mineq\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# m = The total number of constraints\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __zerofun() missing 1 required positional argument: 'targets'"
     ]
    }
   ],
   "source": [
    "## Set your slack variable C\n",
    "C = 100\n",
    "\n",
    "## Compute the P matrix\n",
    "P = __compute_P_mat(targets, inputs, kernel = linearKernel)\n",
    "alpha_0 = np.zeros(n_train)\n",
    "bounds = [(0, C) for b in range(n_train)]\n",
    "constraint = {'type':'eq', 'fun':__zerofun}\n",
    "\n",
    "__min = minimize(__objective, alpha_0, bounds = bounds, constraints = constraint)\n",
    "\n",
    "# use the string 'x' as an index to pick out the actual alpha values\n",
    "alpha = __min.x\n",
    "\n",
    "# see if the optimizer found a solution\n",
    "if __min.success:\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"ERROR: Optimization didnt converge\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2211717-89a1-448e-82e0-00bd8261f9ba",
   "metadata": {},
   "source": [
    "### 3.2.5 Extract the non-zero α values\n",
    "\n",
    "If the data is well separated, only a few of the α values will be non-zero. Since we are dealing with floating point values, however, those that are supposed to be zero will in reality only be approximately zero. Therefore, use a low threshold (10−5 should work fine) to determine which are to be regarded as non-zero.\n",
    "\n",
    "You need to save the non-zero αi’s along with the corresponding data points (xi) and target values (ti) in a separate data structure, for instance a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7ea60-0239-43c0-a6cf-78eb94d90bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "\n",
    "non_zero_vals = []\n",
    "for i in range(len(alpha)):\n",
    "    if alpha[i] > epsilon:\n",
    "        non_zero_vals.append((alpha[i], inputs[i], targets[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391762d2-85ae-46f0-83c7-3e6c6f395755",
   "metadata": {},
   "source": [
    "### 3.2.6 Calculate the b value\n",
    "Note that you must use a point on the margin. This corresponds to a\n",
    "point with an α-value larger than zero, but less than C (if slack is used). To compute the b value we need to use equation 5-12 from the book:\n",
    "\\begin{align}\n",
    "\\hat{b} = \\frac{1}{n_s} \\sum_{i=1}^m \\left( t^{i} - \\sum_{j=1}^m \\hat{\\alpha}^{(j)} t^{(j)} K(x^{(i)},x^{(j)}) \\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a7c1b-45c0-4c90-9d3c-370388e0736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __compute_b():\n",
    "    support_vector = non_zero_vals[0][1]\n",
    "    t_support = non_zero_vals[0][2]\n",
    "    \n",
    "    for alpha, x, t in non_zero_vals:\n",
    "        if alpha < C:\n",
    "            t_support = t\n",
    "            support_vector = x\n",
    "\n",
    "    if t_support == 0:\n",
    "        print(\"ERROR: Couldn't find alpha < C\")\n",
    "        return 0\n",
    "\n",
    "    b_result = 0\n",
    "    for alpha, x, t in non_zero_vals:\n",
    "        b_result += alpha*t*kernel(support_vector, x)\n",
    "    return b_result - t_support\n",
    "\n",
    "b = __compute_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45385d5-dd0c-4985-b0ae-af02f9d29062",
   "metadata": {},
   "source": [
    "### 3.2.7 Implement the indicator function\n",
    "Implement the indicator function which uses the non-zero $\\alpha_{i}$’s together with their xi’s and ti’s to classify new points. This corresponds to equation 5-11 from the book:\n",
    "\n",
    "\\begin{align}\n",
    "h_{\\hat{w},\\hat{b}}(\\phi (x^{(n)})) = \\sum_{i=1}^m \\hat{\\alpha}^{(i)} t^{(i)} K(x^{(i)},x^{(n)}) - \\hat{b}\n",
    "\\end{align}\n",
    "where \n",
    "$\\hat{\\alpha}^{(i)} > 0$\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d1a43-9d1f-4492-809e-86ad9c75680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator(point):\n",
    "\n",
    "    ## TO DO ##\n",
    "    total = 0\n",
    "    for alpha, xi, ti in non_zero_vals:\n",
    "        total += alpha * ti * kernel(xi, point)\n",
    "        \n",
    "    return total - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5bc520-a539-457f-be63-8a74939ca83a",
   "metadata": {},
   "source": [
    "# 4. Plotting\n",
    "\n",
    "In order to see your data, you can use the plot functions from matplotlib. This code will plot your two classes using blue and red dots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ddd1a-6b73-4efb-8d41-548c4fdfd145",
   "metadata": {},
   "source": [
    "## 4.1. Plotting the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134946d3-ee37-4af4-9421-cd580f3aa882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(classA, classB):\n",
    "        plt.plot( [ p[0] for p in classA], [ p[1] for p in classA], 'b. ' )\n",
    "        plt.plot( [ p[0] for p in classB], [ p[1] for p in classB], 'r. ' )\n",
    "\n",
    "        xgrid = np.linspace(-5, 5)\n",
    "        ygrid = np.linspace(-3, 3)\n",
    "        grid = np.array([[indicator(np.array((x,y)))\n",
    "                            for x in xgrid]\n",
    "                            for y in ygrid])\n",
    "\n",
    "        plt.contour(xgrid, ygrid, grid, (-1.0, 0.0, 1.0),\n",
    "                    colors = (\"red\", \"black\", \"blue\"),\n",
    "                    linewidths = (1, 3, 1))\n",
    "        plt.title(kernel)\n",
    "        plt.axis('equal')           # Force same scale on both axes\n",
    "        plt.savefig('svmplot.png')  # Save a copy in a file\n",
    "        plt .show()                 # Show the plot on the screen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465a341-c3b9-4929-a6d2-417492e32fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(classA, classB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2331fc-dabf-492a-b542-ba11604c1b2b",
   "metadata": {},
   "source": [
    "# 5. Exploring and Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb03132-d270-468d-9711-0f101db5b119",
   "metadata": {},
   "source": [
    "## 5.1 Exploring with linear kernel\n",
    "(1) Move the clusters in the given dataset around and change their sizes to make it easier or harder for the linear classifier to find a good boundary (for example by overlapping the dataset). Illustrate your answer using labelled plots.\n",
    "\n",
    "(2) Describe whether the optimizer fails to converge in some cases and why. Illustrate your answer using labelled plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e1285-f16c-4cb8-a966-c65222d7c3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ee1ea-d508-4e6c-92ca-f51f45d217d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b14ec966-fe4d-48ba-957f-ef91973a0bcf",
   "metadata": {},
   "source": [
    "## 5.2 Testing non-linear kernels\n",
    "Once you have the linear kernel up and running, you can explore a dataset that is not linearly separable.\n",
    "\n",
    "(1) Try to use a polynomial kernel to classify the dataset below.\n",
    "\n",
    "(2) Try to use an rbf kernel to classify the dataset below. Below is an example of how the RBF kernel could look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d2648-68f0-41f8-92cc-c565761a198b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a0a0d-b48a-4b78-8a12-7f60c5352c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cb41d23-ffa5-426a-ae70-a71f18ccd403",
   "metadata": {},
   "source": [
    "## 5.3 Kernel parameters\n",
    "\n",
    "(1) Explore how the degree parameter of the polynomial kernel influences the decision boundary. Reason about this in terms of the bias variance trade-off. Explain using plots.\n",
    "\n",
    "(2) Explore how the gamma parameter of the RBF kernel influences the decision boundary. Reason about this in terms of the bias variance trade-off. Explain using plots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "338f8061-25ea-434e-ada5-53c96b684bae",
   "metadata": {},
   "source": [
    "## 5.4 Slack parameter\n",
    "Explore the role of the slack parameter C for the various kernels. What happens for very large/small values? Illustrate your answer with plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787b500-52f1-46eb-b2a9-b8be822dce55",
   "metadata": {},
   "source": [
    "## 5.5 Sklearn SVM\n",
    "Sklearn have a package for implementing SVMs. Apply this model to the generated data - how does the RBF kernel compare with the ones you have created? Explain using plots. Hint: You can make use of the model.decision function to plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987cf5ff-a44d-47a6-b8ee-94ff2d7125c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVC = svm.SVC(kernel = 'rbf', C=1, gamma = 1)\n",
    "SVC.fit(inputs, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
